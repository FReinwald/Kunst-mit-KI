{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "from options.test_options import TestOptions\n",
    "from options.train_options import TrainOptions\n",
    "from data import create_dataset\n",
    "from models import create_model\n",
    "# from util.visualizer import save_images\n",
    "from util import html\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from helper_demo import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face to cartoon\n",
    "The images from the real face dataset are very well illuminated and taken by a qualitative setup. Images from the testset are transformed very well to cartoons. To show a real-world performance we run webcam images through the network to see if they still produce an output.\n",
    "\n",
    "In the first part we have to setup our model and load the weights. We provide pretrained networks for different lambdas and a demo option where we have picked the best models we got.\n",
    "\n",
    "Then we use opencv to capture the video camera and matplotlib to show the current conversions. To stop the loop you have to interrupt the (Jupyter) Kernel.\n",
    "\n",
    "In order to use the bonus part you have to download and install the full dataset.\n",
    "\n",
    "Have fun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/faces              \n",
      "             dataset_mode: face                          \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 100                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                        f: /home/fabian/.local/share/jupyter/runtime/kernel-70a7a956-7b5f-4c75-977e-d9996c7f7045.json\t[default: ignore this]\n",
      "                 gan_mode: lsgan                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                 lambda_A: 10.0                          \n",
      "                 lambda_B: 10.0                          \n",
      "          lambda_identity: 0.0                           \n",
      "          lambda_landmark: 0.01                          \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: cycle_gan                     \n",
      "               n_layers_D: 3                             \n",
      "                     name: cartoonfaces                  \n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "                    niter: 100                           \n",
      "              niter_decay: 200                           \n",
      "               no_dropout: True                          \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: instance                      \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 50                            \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 100                           \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      ">>> CondResnetGenerator 1!!!!!!!!!!\n",
      "in CondResnetGenerator: device= cuda:0\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [CycleGANModel] was created\n",
      "loading the model from ./checkpoints/goblin/latest_net_G_A.pth\n",
      "loading the model from ./checkpoints/goblin/latest_net_G_B.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G_A] Total number of parameters : 11.444 M\n",
      "[Network G_B] Total number of parameters : 11.378 M\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# setup cyclegan model using the training options\n",
    "opt = helper.setup_options()\n",
    "\n",
    "# we provide different pretrained models\n",
    "#opt.name=\"cartoonfaces\"           #landmark lambda of 0.001\n",
    "#opt.name=\"cartoonfaces-ld0_0001\"  #landmark lambda of 0.0001\n",
    "#opt.name=\"cartoonfaces-ld0_00001\" #landmark lambda of 0.00001\n",
    "#opt.name=\"cartoonfaces-ld0_0\"     #landmark lambda of 0.0\n",
    "#opt.name=\"demo\"                    #best choice for G_A and G_B.\n",
    "opt.name = \"goblin\"\n",
    "\n",
    "model = create_model(opt)\n",
    "model.isTrain = False\n",
    "model.setup(opt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert faces to cartoons (forward pass through the network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e0bb8e3b513b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# scale the image and convert to RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mhight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mcrop_pixel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mhight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# crop square\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mcropped_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_pixel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcrop_pixel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# control the \"zoom\" with the framesize:\n",
    "# 256x256 will be cropped out from the center.\n",
    "# use this as initial frame size:\n",
    "framesize = 500\n",
    "\n",
    "# capture on webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_BUFFERSIZE, 1);\n",
    "\n",
    "# use the hflip for \"demirrored\" webcams\n",
    "transform = transforms.Compose([torchvision.transforms.functional.hflip,\n",
    "                                transforms.CenterCrop(256),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                (0.5, 0.5, 0.5))])\n",
    "\n",
    "style = 0\n",
    "style2 = 1\n",
    "style_counter = True\n",
    "\n",
    "try:\n",
    "    while(True):\n",
    "        # drop capture buffer (the easy way)\n",
    "        ret, frame = cap.read()\n",
    "        ret, frame = cap.read()\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # update style\n",
    "        if style_counter:\n",
    "            style = ((style + 1) % 10)\n",
    "            style2 = ((style2 + 1) % 10)\n",
    "\n",
    "        # scale the image and convert to RGB\n",
    "        hight, width, depth = frame.shape\n",
    "        crop_pixel = int((width - hight)/2) # crop square\n",
    "        cropped_frame = frame[:, crop_pixel:width-crop_pixel]\n",
    "        resized_frame = cv2.resize(cropped_frame, (framesize, framesize))\n",
    "        cvframe = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB) \n",
    "        \n",
    "        # transform the capture to an PIL image\n",
    "        pil_img = Image.fromarray(cvframe)\n",
    "        img = transform(pil_img)\n",
    "        img = img.view(1, 3, 256, 256)\n",
    "        img_A = helper.to_image(img)\n",
    "        \n",
    "        img_B = model.gen_B(img, style+1)\n",
    "        img_B2 = model.gen_B(img, style2+1)\n",
    "        img_B = helper.to_image(img_B)\n",
    "        img_B2 = helper.to_image(img_B2)\n",
    "        img_AB = helper.concatenate([img_A, img_B, img_B2])\n",
    "        img_AB.save('comic.jpg')\n",
    "        \n",
    "        clear_output()\n",
    "        plt.axis('off')\n",
    "        plt.title('Generated cartoon image style {} and {}'.format(style+1, style2+1))\n",
    "        plt.imshow(img_AB)\n",
    "        plt.show()        \n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    # you have to interrupt the kernel to break the loop:\n",
    "    cap.release()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the image is too dark, put a lamp in front of your face. This improves the overall illumination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize training data\n",
    "To run this part you need to setup the dataset. Instructions are under `../README.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "./datasets/faces\\test is not a valid directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-34f576245c8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# setup dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# and some real faces from the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - stud.hs-heilbronn.de\\HHN\\WS2122\\Semesterarbeit\\face-to-cartoon\\code\\data\\__init__.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[1;34m(opt)\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \"\"\"\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0mdata_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCustomDatasetDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - stud.hs-heilbronn.de\\HHN\\WS2122\\Semesterarbeit\\face-to-cartoon\\code\\data\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, opt)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mdataset_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_dataset_using_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dataset [%s] was created\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         self.dataloader = torch.utils.data.DataLoader(\n",
      "\u001b[1;32m~\\OneDrive - stud.hs-heilbronn.de\\HHN\\WS2122\\Semesterarbeit\\face-to-cartoon\\code\\data\\face_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, opt)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphase\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA_root\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_dataset_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m                 \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA_paths\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - stud.hs-heilbronn.de\\HHN\\WS2122\\Semesterarbeit\\face-to-cartoon\\code\\data\\image_folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[1;34m(dir, max_dataset_size)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_dataset_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"inf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'%s is not a valid directory'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfnames\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: ./datasets/faces\\test is not a valid directory"
     ]
    }
   ],
   "source": [
    "# setup dataset\n",
    "dataset = create_dataset(opt)\n",
    "\n",
    "# and some real faces from the dataset\n",
    "for i, data in enumerate(dataset):\n",
    "    if (i > 5):\n",
    "        break\n",
    "    \n",
    "    theA = data['A']\n",
    "    real_A = theA['img']\n",
    "    img_A = helper.to_image(real_A)\n",
    "    img_B = model.gen_B(real_A, (i%10)+1)\n",
    "    img_B = helper.to_image(img_B)\n",
    "    img_AB = helper.concatenate([img_A, img_B])\n",
    "    img_AB.save('comic2.jpg')\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.title('Generated comic image')\n",
    "    plt.imshow(img_AB)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: convert cartoons to faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(dataset):\n",
    "    if (i > 5):\n",
    "        break\n",
    "    \n",
    "    theB = data['B']\n",
    "    real_B = theB['img']\n",
    "    img_B = helper.to_image(real_B)\n",
    "    img_A = model.gen_A(real_B)\n",
    "    img_A = helper.to_image(img_A)\n",
    "    img_BA = helper.concatenate([img_B, img_A])\n",
    "    img_BA.save('real.jpg')\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.title('Generated face image')\n",
    "    plt.imshow(img_BA)\n",
    "    plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
