{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "from options.test_options import TestOptions\n",
    "from options.train_options import TrainOptions\n",
    "from data import create_dataset\n",
    "from models import create_model\n",
    "from util.visualizer import save_images\n",
    "from util import html\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from helper_demo import helper\n",
    "\n",
    "# Restart IPython kernel to take changes into effect after editing a module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model architecture / Load latest model weights / Create cartoon dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup cyclegan model using the training options\n",
    "opt = helper.setup_options()\n",
    "\n",
    "model = create_model(opt)\n",
    "model.isTrain = False\n",
    "model.setup(opt)\n",
    "\n",
    "# setup dataset\n",
    "dataset = create_dataset(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert faces to cartoons (forward pass through the network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# set the brightness in order to enhance captures in a \n",
    "# dark environment (default 0.5)\n",
    "brightness = 0.3 # lower enhances darker environments\n",
    "\n",
    "# capture on webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_BUFFERSIZE, 1);\n",
    "# use the hflip for \"demirrored\" webcams\n",
    "transform = transforms.Compose([torchvision.transforms.functional.hflip,\n",
    "                                transforms.CenterCrop(256),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((brightness, brightness, brightness),\n",
    "                                                (0.5, 0.5, 0.5))])\n",
    "\n",
    "style = 0\n",
    "style_counter = True\n",
    "framesize = 600\n",
    "\n",
    "try:\n",
    "    while(True):\n",
    "        # drop capture buffer (the easy way)\n",
    "        ret, frame = cap.read()\n",
    "        ret, frame = cap.read()\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # update style\n",
    "        if style_counter:\n",
    "            style = ((style + 1) % 10)\n",
    "\n",
    "        # scale the image and convert to RGB\n",
    "        hight, width, depth = frame.shape\n",
    "        crop_pixel = int((width - hight)/2) # crop square\n",
    "        cropped_frame = frame[:, crop_pixel:width-crop_pixel]\n",
    "        resized_frame = cv2.resize(cropped_frame, (framesize, framesize))\n",
    "        cvframe = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB) \n",
    "        \n",
    "        # transform the capture to an PIL image\n",
    "        pil_img = Image.fromarray(cvframe)\n",
    "        img = transform(pil_img)\n",
    "        img = img.view(1, 3, 256, 256)\n",
    "        img_A = helper.to_image(img[0, :, :, :])\n",
    "        \n",
    "        img_B = model.gen_B(img, style+1)\n",
    "        #torchvision.utils.save_image(img_B[0, :, :, :], 'comic.png')\n",
    "        img_B = helper.to_image(img_B[0, :, :, :])\n",
    "        img_AB = helper.concatenate([img_A, img_B])\n",
    "        img_AB.save('comic.jpg')\n",
    "\n",
    "        clear_output()\n",
    "        plt.axis('off')\n",
    "        plt.title('Generated cartoon image style {}'.format(style+1))\n",
    "        plt.imshow(img_AB)\n",
    "        plt.show()\n",
    "            \n",
    "        # Interrupt the kernel to stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the image is too dark, put a lamp in front of your face (classical computer vision trick). You can finetune with the brightness property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: convert cartoons to faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(dataset):\n",
    "    if (i > 5):\n",
    "        break\n",
    "    \n",
    "    theB = data['B']\n",
    "    real_B = theB['img']\n",
    "    img_B = helper.to_image(real_B[0,:,:,:])\n",
    "    img_A = model.gen_A(real_B)\n",
    "    img_A = helper.to_image(img_A[0,:,:,:])\n",
    "    img_BA = helper.concatenate([img_B, img_A])\n",
    "    img_BA.save('real.jpg')\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.title('Generated face image')\n",
    "    plt.imshow(img_BA)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## demo code to have a slider for the conditional version\n",
    "\n",
    "import ipywidgets as wg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class interactive_plot:\n",
    "\n",
    "    def __init__(self,r):\n",
    "        self.X = [x for x in range(r)]\n",
    "        self.Y = [y for y in range(r)]\n",
    "        self.r = r\n",
    "        self.fig = None\n",
    "        self.ax = None\n",
    "\n",
    "    def pathPlot(self, xframe = None):\n",
    "\n",
    "        if self.fig is None:\n",
    "            self.fig = plt.figure()\n",
    "            self.ax =self.fig.add_subplot(1,1,1)\n",
    "            self.ax.plot(self.X, self.Y, 'bo-')\n",
    "\n",
    "        else:\n",
    "            self.fig = plt.gcf()\n",
    "            self.ax = plt.gca()\n",
    "            self.ax.plot(self.X, self.Y, 'bo-')\n",
    "\n",
    "        if xframe is not None:\n",
    "            self.ax.axvline(x = self.X[xframe],color = 'black',linestyle = '--')\n",
    "            self.ax.plot(self.X[xframe],self.Y[xframe], 'ro', markersize=10)\n",
    "\n",
    "    def pathPlay(self):\n",
    "\n",
    "        frame = wg.IntSlider(min = 0, max = self.r - 1)\n",
    "        wg.interact(self.pathPlot, xframe = frame)\n",
    "\n",
    "test = interactive_plot(10)\n",
    "test.pathPlay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
