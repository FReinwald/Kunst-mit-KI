{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face to Cartoon with cycleGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Project in Advanced Topics of Machine Learning (FS2019)\n",
    "\n",
    "##### Guodong Zeng, Benjamin Fankhauser, Jan Segessenmann, Gautam Ilango"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction \n",
    "\n",
    "Our goal is to switch image styles from a real faces to cartoon faces using unpaired data only. Some of the important features of the real faces should be preserved and recognized in the generated cartoon faces.  \n",
    "As a starting point, we use an implementation of cycleGAN introduced by Jun-Yan Zhu et al. [1] cycleGAN achieves impressive results in learning the mapping between different styles of images (e.g. paintings $\\to$ photos, zebras $\\to$ horses or summer $\\to$ winter and vice versa).  \n",
    "\n",
    "\n",
    "\n",
    "In order to incorporate additional prior knowledge to the architecture we add another loss term based on landmark predictions for both, the real faces and the cartoon faces.\n",
    "To extend the usages of our model we additionally provide a one to ten mapping of real faces to cartoon faces. We make the whole architecutre conditional and train the models with ten different hair colors, so the user is free to choose his or her hair color.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Materials and Methods\n",
    "#### cycleGAN\n",
    "To achieve the unpaired style transfer from real faces to cartoon faces, we have to learn the mapping function $G: A \\to B$, with domain $A$ being real faces and domain $B$ being cartoon faces, such that the distribution of $G(A)$ is as similar as possible to the distribution $B$ by minimizing adversarial loss. Since this mapping is highly under-constrained, Jun-Yan Zhu et al. introduced the coupling of another mapping $H: B \\to A$. The main idea is to minimize the consistency cycle loss $L(A, (H(G(A)))$ as well as the standart adversarial losses.  \n",
    "![scheme](doc/images/cycleGAN_scheme_extended.png)  \n",
    "The above figure is partly adapted from Jun-Yan Zhu et al. [2] and shows the method schematically. The reverse mapping with starting in $B$ is not shown.  \n",
    "\n",
    "[The following would be the short visualization:]\n",
    "![scheme_short](doc/images/cycle_GAN_scheme.png)\n",
    "#### Datasets\n",
    "[...] (Jan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Results\n",
    "[...] (Ben)\n",
    "\n",
    "### Landmarks Loss\n",
    "[...] (Ben)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditions on Hair Color\n",
    "[...] (Guodong)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved cycleGAN\n",
    "[...] (Gautam, with example!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and Outlook\n",
    "[...] (Gautam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliography\n",
    "[1]  \n",
    "[2] Figure is avaiable on: https://github.com/eriklindernoren/PyTorch-GAN#cyclegan\n",
    "[3]  \n",
    "[...] (everyone who needs citations etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
